{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c35b4bf-6e6f-493f-9c3f-080f8ccadb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import json\n",
    "import pandas as pd \n",
    "import re\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a06e1dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306c060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_positions(text:str,\n",
    "                        words:list[str]):\n",
    "    # find all occurrences of word in text\n",
    "    positions = []\n",
    "    for word in words:\n",
    "        for m in re.finditer(word, text):\n",
    "            positions.extend(list(range(m.start(), m.end())))\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0413df30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(text, threshold, chars, words):\n",
    "    target_choices = [\"char\", \"word\"]\n",
    "    operation_choices = [\"insert\", \"delete\", \"substitute\"]  \n",
    "    text_split = text.strip().split()\n",
    "    noise_text_split = []\n",
    "    for token in text_split:\n",
    "        random_float = random.uniform(0, 1)\n",
    "        if random_float <= threshold:\n",
    "            target = random.choice(target_choices)\n",
    "            operation = random.choice(operation_choices)\n",
    "            if target == \"char\":\n",
    "                # protext <answer> </answer> to be untouched by excluding their positions\n",
    "                protected_positions = find_word_positions(text, [\"<answer>\", \"</answer>\", 'python_function', 'necessarily true', 'necessarily false', 'uncertain', 'yes', 'no', \"<answer>yes</answer>\", '0', '1', '2', '3', '4', '5' '6', '7', '8', '9', 'Python'])\n",
    "                token_position = random.choice([_ for _ in range(len(token)) if _ not in protected_positions])\n",
    "                if operation == \"insert\":\n",
    "                    token = token[:token_position] + random.choice(chars) + token[token_position:]\n",
    "                elif operation == \"delete\":\n",
    "                    token = token[:token_position] + token[token_position + 1:]\n",
    "                elif operation == \"substitute\":\n",
    "                    token = token[:token_position] + random.choice(chars) + token[token_position + 1:]\n",
    "            elif target == \"word\":\n",
    "                if operation == \"insert\":\n",
    "                    token = f\"{random.choice(words)} {token}\"\n",
    "                elif operation == \"delete\":\n",
    "                    token = \"\"\n",
    "                elif operation == \"substitute\":\n",
    "                    token = random.choice(words)\n",
    "        if token:\n",
    "            noise_text_split.append(str(token))\n",
    "    return \" \".join(noise_text_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6ff2a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_data = pd.read_csv(\"./wordFrequency.csv\")\n",
    "words = frequency_data.lemma.drop_duplicates().tolist()\n",
    "chars = string.ascii_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7dc8f26-1a90-4b9b-8ef0-a75908897f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_dic = {}\n",
    "for task in ['comprehensive', 'algorithm', 'logic', 'math']:\n",
    "    prompt_dic[task] = [ele['prompt'] for ele in json.load(open(f'../redial/redial_gold/{task}.json', 'r'))['vanilla']['original']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9771c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_prompt_dic = dict()\n",
    "\n",
    "for threshold in [0.02, 0.04, 0.06]:\n",
    "    perturbed_prompt_dic[threshold] = dict()\n",
    "    for task, prompts in prompt_dic.items():\n",
    "        perturbed_prompt_dic[threshold][task] = {'vanilla':{'original':[]}}\n",
    "        for prompt in prompts:\n",
    "            perturbed_prompt_dic[threshold][task]['vanilla']['original'].append(add_noise(prompt, threshold, chars, words))\n",
    "\n",
    "for threshold, task_dic in perturbed_prompt_dic.items():\n",
    "    for task, data in task_dic.items():\n",
    "        json.dump(data, open(f'../redial/perturbations/{threshold}/{task}.json', 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f765ff7c",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb7c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "# load your model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"model\",\n",
    "                                          token='token')\n",
    "model = AutoModelForCausalLM.from_pretrained(\"model\",\n",
    "                                             device_map='auto',\n",
    "                                             token='token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7c4560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(text:str,\n",
    "                         model=model,\n",
    "                         tokenizer=tokenizer):\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    \n",
    "    # Move tensors to the appropriate device\n",
    "    inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
    "    \n",
    "    # Get model outputs\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs['input_ids'])\n",
    "    \n",
    "    # Calculate log-likelihood\n",
    "    log_likelihood = outputs.loss.item()\n",
    "    \n",
    "    # Calculate perplexity\n",
    "    perplexity = torch.exp(torch.tensor(log_likelihood))\n",
    "    \n",
    "    return perplexity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20014ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_dic = dict()\n",
    "\n",
    "for threshold, data in perturbed_prompt_dic.items():\n",
    "    ppl_dic[threshold] = dict()\n",
    "    for task, prompts in data.items():\n",
    "        ppl_dic[threshold][task] = list()\n",
    "        for prompt in tqdm(prompts['vanilla']['original']):\n",
    "            ppl_dic[threshold][task].append(calculate_perplexity(prompt))\n",
    "    print(f\"Threshold {threshold} done\")\n",
    "    # print mean ppl of the threshold data\n",
    "    all_ppls = [v for val in ppl_dic[threshold].values() for v in val]\n",
    "    print(f'Averaged ppl {round(np.mean(all_ppls), 1)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
