{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"model\",\n",
    "                                          token='token')\n",
    "model = AutoModelForCausalLM.from_pretrained(\"model\",\n",
    "                                             device_map='auto',\n",
    "                                             token='token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(text:str,\n",
    "                         model=model,\n",
    "                         tokenizer=tokenizer):\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    \n",
    "    # Move tensors to the appropriate device\n",
    "    inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
    "    \n",
    "    # Get model outputs\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs['input_ids'])\n",
    "    \n",
    "    # Calculate log-likelihood\n",
    "    log_likelihood = outputs.loss.item()\n",
    "    \n",
    "    # Calculate perplexity\n",
    "    perplexity = torch.exp(torch.tensor(log_likelihood))\n",
    "    \n",
    "    return perplexity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "ppl_dic = dict()\n",
    "for file in ['logic', 'comprehensive', 'math', 'algorithm']:\n",
    "    ppl_dic[file.replace('.json', '')] = dict()\n",
    "    data = json.load(open(f'../redial/redial_gold/{file}.json'))\n",
    "    for dia in ['aave', 'original']:\n",
    "        ppl_dic[file.replace('.json', '')][dia] = list()\n",
    "        prompts = [d['prompt'] for d in data['vanilla'][dia]]\n",
    "        for prompt in tqdm(prompts):\n",
    "            ppl_dic[file.replace('.json', '')][dia].append(calculate_perplexity(prompt))\n",
    "            with open(f'../redial/redial_gold/model_ppl.json', 'w') as f:\n",
    "                json.dump(ppl_dic, f)\n",
    "        print(f'The average perplexity of {dia} prompts in {file} is {round(np.mean(ppl_dic[file.replace(\".json\", \"\")][dia]), 1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate averaged perplexity over all instances per dialect\n",
    "aave_ppl = list()\n",
    "original_ppl = list()\n",
    "for file in ppl_dic:\n",
    "    aave_ppl.extend(ppl_dic[file]['aave'])\n",
    "    original_ppl.extend(ppl_dic[file]['original'])\n",
    "print(f'The average perplexity of aave prompts is {round(np.mean(aave_ppl), 1)}')\n",
    "print(f'The average perplexity of original prompts is {round(np.mean(original_ppl), 1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reprint all perplexities with round 3\n",
    "for file in ppl_dic:\n",
    "    print(f'{file}: {round(np.mean(ppl_dic[file][\"aave\"]), 1)} {round(np.mean(ppl_dic[file][\"original\"]), 1)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
